# -*- coding: utf-8 -*-
"""Lab1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ldPiK9XRh1s8iow81taeHTua8Dka9CZp
"""

import torch
import torchvision
from torchvision.datasets import CIFAR10
import torch.optim as optim
import torch.nn.functional as F
import torch.nn as nn
import torchvision.transforms as tf
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import numpy as np


class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=(2, 2), stride=1, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d((2, 2))
        )
        self.conv2 = nn.Sequential(
            nn.Conv2d(32, 64, kernel_size=(2, 2), stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d((2, 2))
        )
        self.conv3 = nn.Sequential(
            nn.Conv2d(64, 128, kernel_size=(2, 2), stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d((2, 2))
        )
        self.fc1 = nn.Linear(2048, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = x.view(-1, 4 * 4 * 128)

        x = self.fc1(x)
        x = F.relu(x)
        x = self.fc2(x)
        x = F.relu(x)
        x = self.fc3(x)

        return x


def train(epoch,model):
    CNN = model
    train_accuracy = 0
    train_loss = 0
    total = 0
    N_count = 0
    for batch, (X, label) in enumerate(train_data):
        X, label = X.to(device), label.to(device)

        N_count += X.size(0)
        optimizer.zero_grad()

        output = CNN(X)
        loss = criterion(output, label)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        _, predicted = torch.max(output, 1)
        total += label.size(0)
        train_accuracy = accuracy_score(label.cpu().data.squeeze().numpy(), predicted.cpu().data.squeeze().numpy())


    print('Train Epoch: {} [{}/{}] \tLoss: {:.6f}, Accuracy: {:.2f}%'.format(
        epoch + 1, N_count, len(train_data.dataset), train_loss / len(train_data),
        100 * (train_accuracy)))

    return 100 * train_accuracy, train_loss / N_count

def test(epoch,model):
    CNN = model
    CNN.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for X, label in test_data:
            X, label = X.to(device), label.to(device)

            output = CNN(X)
            loss = criterion(output, label)
            test_loss += loss.item()

            _,pred = torch.max(output,1)
            acc = accuracy_score(label.cpu().data.squeeze().numpy(), pred.cpu().data.squeeze().numpy())

    test_loss /= len(test_data)
    print('\nTest set ({:d} samples): Average loss: {:.4f}, Accuracy: {:.2f}%\n'.format(len(test_data),
                                                                                      test_loss,
                                                                                      100 * acc))
    return test_loss / len(test_data), 100*acc


if __name__ == '__main__':
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    batch_size = 100
    epochs = 50

    transform = tf.Compose([tf.ToTensor(), tf.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])
    dataset_train = CIFAR10(root=r'C:\MyFiles\DLLabs\Lab1\Dataset\train', train=True, transform=transform,
                            download=True)
    train_data = DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True, num_workers=2)
    dataset_test = CIFAR10(root=r'C:\MyFiles\DLLabs\Lab1\Dataset\test', train=False, transform=transform,
                           download=True)
    test_data = DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False, num_workers=2)

    CNN = CNN().to(device)
    if torch.cuda.device_count() > 1:
        CNN = nn.DataParallel(CNN)

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(CNN.parameters(), lr=0.0001)

    train_loss = []
    test_loss = []

    train_accuracy = []
    test_accuracy = []
    for epoch in range(epochs):
        train_acc, train_losses = train(epoch, CNN)
        test_losses,test_acc = test(epoch,CNN)
        train_accuracy.append(train_acc)
        train_loss.append(train_losses)
        test_accuracy.append(test_acc)
        test_loss.append(test_losses)

    fig, ax = plt.subplots()
    plt.plot(train_loss, label='Train')
    plt.plot(test_loss, label='Test')
    plt.title('Loss of train data(blue color) and loss of test data(orange color)')
    plt.ylabel('Loss')
    plt.xlabel('Number of epoch')
    fig.savefig('Loss.png')
    plt.show()
    plt.close()

    fig1, ax1 = plt.subplots()
    plt.plot(train_accuracy, label='Train')
    plt.plot(test_accuracy, label='Test')
    plt.title('Accuracy of train data(blue color) and accuracy of test data(orange color)')
    plt.ylabel('Accuracy')
    plt.xlabel('Number of epoch')
    fig1.savefig('Accuracy.png')
    plt.show()
    plt.close()

    print('Total train epochs Accuracy = ', str(sum(train_accuracy) / len(train_accuracy)))
    print('Total test epochs Accuracy = ', str(sum(test_accuracy) / len(test_accuracy)))
    print('Total train epochs Loss = ', str(sum(train_loss) /
                                            len(train_loss)))
    print('Total test epochs Loss = ', str(sum(test_loss) /len(test_loss)))